### Introduction to Multi-Armed Bandits

<https://arxiv.org/abs/1904.07272>

-
-
-
- (188 page text)


### Contextual Bandits with Linear Payoff Functions

<https://proceedings.mlr.press/v15/chu11a/chu11a.pdf>

-
-
-


### Regret Analysis of Stochastic and Nonstochastic Multi-armed Bandit Problems

<https://arxiv.org/abs/1204.5721>

-
-
-


### Bandit based Monte-Carlo Planning

<http://ggp.stanford.edu/readings/uct.pdf>

-
-
-


### A Survey of Online Experiment Design with the Stochastic Multi-Armed Bandit

<https://arxiv.org/abs/1510.00757>

-
-
-
  
