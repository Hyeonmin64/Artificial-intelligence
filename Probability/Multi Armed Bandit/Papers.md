### Introduction to Multi-Armed Bandits

<https://arxiv.org/abs/1904.07272>

-
-
-
- (188 page text)


### Contextual Bandits with Linear Payoff Functions

<https://proceedings.mlr.press/v15/chu11a/chu11a.pdf>

-
-
-


### Regret Analysis of Stochastic and Nonstochastic Multi-armed Bandit Problems

<https://arxiv.org/abs/1204.5721>

-
-
-


### Bandit based Monte-Carlo Planning

<http://ggp.stanford.edu/readings/uct.pdf>

-
-
-


### A Survey of Online Experiment Design with the Stochastic Multi-Armed Bandit

<https://arxiv.org/abs/1510.00757>

-
-
-


https://arxiv.org/pdf/2101.12204.pdf

https://sites.socsci.uci.edu/~ivan/asmb.874.pdf

https://proceedings.neurips.cc/paper_files/paper/2008/file/49ae49a23f67c759bf4fc791ba842aa2-Paper.pdf

https://proceedings.mlr.press/v22/shivaswamy12.html
